{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import wfdb\r\n",
    "import ast\r\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\r\n",
    "import os\r\n",
    "\r\n",
    "from sklearn.utils import shuffle\r\n",
    "import math\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.preprocessing import StandardScaler,normalize, MinMaxScaler\r\n",
    "\r\n",
    "\r\n",
    "import os\r\n",
    "import wandb\r\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\r\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing \r\n",
    "#   Using the super classes, multi label classification, excluding samples with no labels and considering atleast one label\r\n",
    "\r\n",
    "path = 'ptb/'\r\n",
    "Y = pd.read_csv(path+ 'ptbxl_database.csv', index_col = 'ecg_id')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "data = np.array([wfdb.rdsamp(path+f)[0] for f in Y.filename_lr])\r\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\r\n",
    "    \r\n",
    "agg_df = pd.read_csv(path+ 'scp_statements.csv', index_col = 0)\r\n",
    "\r\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\r\n",
    "\r\n",
    "def agg(y_dic):\r\n",
    "    temp =[]\r\n",
    "    \r\n",
    "    for key in y_dic.keys():\r\n",
    "        if y_dic[key] in [100, 80, 0] :\r\n",
    "            if key in agg_df.index:\r\n",
    "                if key in ['ASMI', 'IMI']:\r\n",
    "\r\n",
    "                    temp.append(key)\r\n",
    "    return list(set(temp))\r\n",
    "\r\n",
    "\r\n",
    "Y['diagnostic_subclass'] = Y.scp_codes.apply(agg)\r\n",
    "Y['subdiagnostic_len'] = Y['diagnostic_subclass'].apply(lambda x: len(x))\r\n",
    "\r\n",
    "## MI\r\n",
    "x_1 = data[Y['subdiagnostic_len'] == 1]\r\n",
    "y_1 = Y[Y['subdiagnostic_len'] == 1]\r\n",
    "\r\n",
    "def norm_agg(y_dic):\r\n",
    "    temp =[]\r\n",
    "    \r\n",
    "    for key in y_dic.keys():\r\n",
    "        if y_dic[key] in [100] :\r\n",
    "            if key == 'NORM':\r\n",
    "                return 'NORM'\r\n",
    "    \r\n",
    "Q = Y.copy()\r\n",
    "Q['diagnostic_subclass'] = Y.scp_codes.apply(norm_agg)\r\n",
    "\r\n",
    "\r\n",
    "## Norm\r\n",
    "x_2 = data[Q['diagnostic_subclass'] == 'NORM']\r\n",
    "y_2 = Q[Q['diagnostic_subclass'] == 'NORM'] \r\n",
    "\r\n",
    "\r\n",
    "x_1_train = x_1[y_1.strat_fold <= 8]\r\n",
    "y_1_train = y_1[y_1.strat_fold <= 8]\r\n",
    "\r\n",
    "x_1_test = x_1[y_1.strat_fold > 8]\r\n",
    "y_1_test = y_1[y_1.strat_fold > 8]\r\n",
    "\r\n",
    "x_2_train = x_2[y_2.strat_fold <= 2][:800]\r\n",
    "y_2_train = y_2[y_2.strat_fold <= 2][:800]\r\n",
    "\r\n",
    "x_2_test = x_2[y_2.strat_fold == 3][:200]\r\n",
    "y_2_test = y_2[y_2.strat_fold == 3][:200]\r\n",
    "\r\n",
    "train_data = np.concatenate((x_1_train, x_2_train), axis = 0)\r\n",
    "test_data = np.concatenate((x_1_test, x_2_test), axis = 0)\r\n",
    "\r\n",
    "y_1_train.diagnostic_subclass = y_1_train.diagnostic_subclass.apply(lambda x : x[0])\r\n",
    "y_1_test.diagnostic_subclass = y_1_test.diagnostic_subclass.apply(lambda x : x[0])\r\n",
    "\r\n",
    "train_label = np.concatenate((y_1_train.diagnostic_subclass.values, y_2_train.diagnostic_subclass.values), axis = 0)\r\n",
    "test_label = np.concatenate((y_1_test.diagnostic_subclass.values, y_2_test.diagnostic_subclass.values), axis = 0)\r\n",
    "\r\n",
    "\r\n",
    "le = LabelEncoder()\r\n",
    "train_label = to_categorical(le.fit_transform(train_label))\r\n",
    "test_label = to_categorical(le.transform(test_label))\r\n",
    "\r\n",
    "train_data, train_label = shuffle(train_data, train_label, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardizing\n",
    "\n",
    "def apply_scaler(X, scaler):\n",
    "    X_tmp = []\n",
    "    for x in X:\n",
    "        x_shape = x.shape\n",
    "        X_tmp.append(scaler.transform(x.flatten()[:,np.newaxis]).reshape(x_shape))\n",
    "    X_tmp = np.array(X_tmp)\n",
    "    return X_tmp\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(np.vstack(train_data).flatten()[:,np.newaxis].astype(float))\n",
    "\n",
    "X_train_scale = apply_scaler(train_data, scaler)\n",
    "X_test_scale = apply_scaler(test_data, scaler)\n",
    "\n",
    "del train_data, test_data, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y,batch_size = 16):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.X) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        X_full = self.X[idx * self.batch_size:(idx + 1) *self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) *self.batch_size]\n",
    "        \n",
    "\n",
    "        return np.transpose(X_full[..., np.newaxis], (0, 2, 1, 3)) ,batch_y\n",
    "    \n",
    "## Params\n",
    "\n",
    "batch_size = 32\n",
    "    \n",
    "train_gen = DataGen(X_train_scale, train_label, batch_size = batch_size)\n",
    "test_gen = DataGen(X_test_scale, test_label, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 12, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "test = train_gen[0][0].shape\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\r\n",
    "\r\n",
    "class attention(tf.keras.layers.Layer):\r\n",
    "    \r\n",
    "    def __init__(self, return_sequences = False, dim = 32, **kwargs):\r\n",
    "        self.return_sequences = return_sequences\r\n",
    "        self.dim = dim\r\n",
    "        super(attention,self).__init__(**kwargs)\r\n",
    "        \r\n",
    "    def build(self, input_shape):\r\n",
    "        \r\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1], self.dim),\r\n",
    "                               initializer=\"normal\")\r\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1], self.dim),\r\n",
    "                               initializer=\"zeros\")\r\n",
    "        self.V = self.add_weight(name = \"Vatt\", shape = (self.dim, 1), initializer = \"normal\")\r\n",
    "        \r\n",
    "        super(attention,self).build(input_shape)\r\n",
    "        \r\n",
    "    def call(self, x):\r\n",
    "        \r\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\r\n",
    "        e = K.dot(e, self.V)\r\n",
    "        a = K.softmax(e, axis=1)\r\n",
    "        output = x*a\r\n",
    "        \r\n",
    "        if self.return_sequences :\r\n",
    "            return output, a\r\n",
    "        \r\n",
    "        return K.sum(output, axis=1), a\r\n",
    "\r\n",
    "    def get_config(self):\r\n",
    "        base_config = super().get_config()\r\n",
    "        config = {\"return sequences\" : tf.keras.initializers.serialize(self.return_sequences), \"att dim\" : tf.keras.initializers.serialize(self.dim)}\r\n",
    "        return dict(list(base_config.items()) + list(config.items()))\r\n",
    "    \r\n",
    "## Resnet blocks\r\n",
    "\r\n",
    "def relu_bn(inputs: tf.Tensor) -> tf.Tensor:\r\n",
    "    \r\n",
    "    \r\n",
    "    dp = Dropout(0.5)(inputs)\r\n",
    "    relu = ReLU()(dp)\r\n",
    "    bn = BatchNormalization()(relu)\r\n",
    "    return bn\r\n",
    "\r\n",
    "\r\n",
    "def residual_block(x: tf.Tensor, downsample: bool, filters: int, kernel_size: int = 12) -> tf.Tensor:\r\n",
    "    \r\n",
    "    y = Conv1D(kernel_size=kernel_size,\r\n",
    "               strides= (1 if not downsample else 2),\r\n",
    "               filters=filters,\r\n",
    "               padding=\"same\")(x)\r\n",
    "    y = relu_bn(y)\r\n",
    "    y = Conv1D(kernel_size=kernel_size,\r\n",
    "               strides=1,\r\n",
    "               filters=filters,\r\n",
    "               padding=\"same\")(y)\r\n",
    "\r\n",
    "    if downsample:\r\n",
    "        x = Conv1D(kernel_size=1,\r\n",
    "                   strides=2,\r\n",
    "                   filters=filters,\r\n",
    "                   padding=\"same\")(x)\r\n",
    "    out = Add()([x, y])\r\n",
    "    out = relu_bn(out)\r\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Params\n",
    "\n",
    "sig_len = 1000\n",
    "beat_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 12, 1000, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 50, 1)]      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 50, 16)       144         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 50, 16)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 16)       2064        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 50, 16)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50, 16)       64          re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 50, 16)       2064        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 50, 16)       0           activation[0][0]                 \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 50, 16)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 16)       64          re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 50, 16)       2064        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 50, 16)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, 16)       64          re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 50, 16)       2064        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 50, 16)       0           batch_normalization_1[0][0]      \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 50, 16)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 50, 16)       64          re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 25, 32)       4128        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 25, 32)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 25, 32)       128         re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 25, 32)       544         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 25, 32)       8224        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 25, 32)       0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 25, 32)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 32)       128         re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 25, 32)       8224        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 25, 32)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 32)       128         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 25, 32)       8224        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 25, 32)       0           batch_normalization_5[0][0]      \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 25, 32)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 32)       128         re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 13, 64)       16448       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 13, 64)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 13, 64)       256         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 13, 64)       2112        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 13, 64)       32832       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 64)       0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 13, 64)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 13, 64)       256         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 13, 64)       32832       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 13, 64)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 13, 64)       256         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 13, 64)       32832       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 64)       0           batch_normalization_9[0][0]      \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 13, 64)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 64)       256         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "beat_att (attention)            ((None, 64), (None,  2496        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 20, 64)]     0           beat_att[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 20, 64)       24832       tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "rhythm_att (attention)          ((None, 64), (None,  2720        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 12, 64)]     0           rhythm_att[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "channel_att (attention)         ((None, 64), (None,  2464        tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            325         channel_att[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 189,429\n",
      "Trainable params: 188,533\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Input, Attention, LSTM, Activation, Dense, Average,ReLU, BatchNormalization,Add, Reshape, Bidirectional, Concatenate\r\n",
    "\r\n",
    "num_channel = 12\r\n",
    "num_filters = 32\r\n",
    "num_blocks_list = [2, 2, 2]\r\n",
    "\r\n",
    "inputs = Input(shape = (num_channel, sig_len, 1), batch_size = None)\r\n",
    "\r\n",
    "#### Beat Level \r\n",
    "x = K.reshape(inputs, (-1, beat_size,1 ))\r\n",
    "\r\n",
    "x = Conv1D(32 ,12 ,padding = 'same')(x)\r\n",
    "x = Activation('relu')(x)\r\n",
    "\r\n",
    "for i in range(len(num_blocks_list)):\r\n",
    "    num_blocks = num_blocks_list[i]\r\n",
    "    for j in range(num_blocks):\r\n",
    "        x = residual_block(x, downsample=(j==0 and i!=0), filters=num_filters)\r\n",
    "    num_filters *= 2\r\n",
    "    \r\n",
    "x, _ = attention(name = \"beat_att\")(x)\r\n",
    "\r\n",
    "##### Rhythm level\r\n",
    "x = K.reshape(x,(-1, int(sig_len/beat_size) , 64))\r\n",
    "\r\n",
    "x = Bidirectional(LSTM(32, return_sequences = True))(x)\r\n",
    "x, _ = attention(name = \"rhythm_att\")(x)\r\n",
    "\r\n",
    "\r\n",
    "#### Channel level\r\n",
    "\r\n",
    "x = K.reshape(x, (-1, num_channel, 64))\r\n",
    "x, _ = attention(name = \"channel_att\")(x)\r\n",
    "\r\n",
    "outputs = Dense(5, activation = 'sigmoid')(x)\r\n",
    "\r\n",
    "aux_model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\r\n",
    "\r\n",
    "aux_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy',tf.keras.metrics.AUC(multi_label = True)])\r\n",
    "aux_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('MI_subtypes'):\r\n",
    "    os.mkdir('MI_subtypes')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project = '3_level ASMI, IMI and NORM', name = 'original_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 12, 1000, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 50, 1)]      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 50, 16)       144         tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 50, 16)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 16)       2064        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 50, 16)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50, 16)       64          re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 50, 16)       2064        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 50, 16)       0           activation[0][0]                 \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 50, 16)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 16)       64          re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 50, 16)       2064        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 50, 16)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, 16)       64          re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 50, 16)       2064        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 50, 16)       0           batch_normalization_1[0][0]      \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 50, 16)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 50, 16)       64          re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 25, 32)       4128        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 25, 32)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 25, 32)       128         re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 25, 32)       544         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 25, 32)       8224        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 25, 32)       0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 25, 32)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 32)       128         re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 25, 32)       8224        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 25, 32)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 32)       128         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 25, 32)       8224        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 25, 32)       0           batch_normalization_5[0][0]      \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 25, 32)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 32)       128         re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 13, 64)       16448       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 13, 64)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 13, 64)       256         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 13, 64)       2112        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 13, 64)       32832       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 13, 64)       0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 13, 64)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 13, 64)       256         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 13, 64)       32832       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 13, 64)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 13, 64)       256         re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 13, 64)       32832       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 13, 64)       0           batch_normalization_9[0][0]      \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 13, 64)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 64)       256         re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "beat_att (attention)            ((None, 64), (None,  2496        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 20, 64)]     0           beat_att[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 20, 64)       24832       tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "rhythm_att (attention)          ((None, 64), (None,  2720        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 12, 64)]     0           rhythm_att[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "channel_att (attention)         ((None, 64), (None,  2464        tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            195         channel_att[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 189,299\n",
      "Trainable params: 188,403\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "outputs = Dense(3, activation='softmax')(aux_model.layers[-2].output[0])\n",
    "\n",
    "model = tf.keras.models.Model(inputs = aux_model.input, outputs = outputs)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy',tf.keras.metrics.AUC()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy metric\r\n",
    "\r\n",
    "def metrics(y_true, y_scores):\r\n",
    "    y_pred = y_scores >= 0.5\r\n",
    "    acc = np.zeros(y_pred.shape[-1])\r\n",
    "    \r\n",
    "    for i in range(y_pred.shape[-1]):\r\n",
    "        acc[i] = accuracy_score(y_true[:,i], y_pred[:,i])\r\n",
    "    return acc, np.mean(acc)\r\n",
    "\r\n",
    "## Callback for logging and metrics \r\n",
    "\r\n",
    "class model_checkpoint(tf.keras.callbacks.Callback):\r\n",
    "\r\n",
    "    def __init__(self, filepath, gen, monitor='loss',  options=None, **kwargs):\r\n",
    "\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.filepath = filepath\r\n",
    "        self.monitor = monitor\r\n",
    "        self.test_data = gen\r\n",
    "        \r\n",
    "        \r\n",
    "    def on_epoch_end(self, epoch, logs = {}) :\r\n",
    "        \r\n",
    "        test_len = len(self.test_data)\r\n",
    "        score = []\r\n",
    "        gt =[]\r\n",
    "\r\n",
    "        for i in range(test_len):\r\n",
    "            X,y = self.test_data[i][0], self.test_data[i][1]\r\n",
    "            temp_score = self.model.predict(X)\r\n",
    "            score.append(temp_score)\r\n",
    "            gt.append(y)\r\n",
    "\r\n",
    "        score = np.concatenate(score, axis = 0)\r\n",
    "        gt = np.concatenate(gt, axis = 0)\r\n",
    "        \r\n",
    "        roc_auc = roc_auc_score(gt, score)\r\n",
    "        _, accuracy = metrics(gt, score)\r\n",
    "        \r\n",
    "        temp_path = f\"{epoch+1}_roc_{roc_auc:.4f}.h5\"\r\n",
    "        path = os.path.join(self.filepath, temp_path)\r\n",
    "        \r\n",
    "        \r\n",
    "        self.model.save_weights(path)\r\n",
    "\r\n",
    "        wandb.log({'train_loss' : logs['loss'], 'epoch' : epoch})\r\n",
    "        wandb.log({'train_keras_auroc' : logs.get(self.monitor), 'epoch' : epoch})\r\n",
    "        \r\n",
    "        wandb.log({'test_loss' : logs['val_loss'], 'epoch' : epoch})\r\n",
    "        wandb.log({'test_keras_auroc' : logs['val_auc_1'], 'epoch' : epoch})\r\n",
    "\r\n",
    "        wandb.log({'test_roc_score' : roc_auc, 'epoch' : epoch})\r\n",
    "        wandb.log({'test_accuracy_score' : accuracy, 'epoch' : epoch})\r\n",
    "        \r\n",
    "        logs['val_roc_auc'] = roc_auc\r\n",
    "        logs['val_accuracy_score'] = accuracy\r\n",
    "    \r\n",
    "    def set_model(self, model):\r\n",
    "        self.model = model\r\n",
    "\r\n",
    "        \r\n",
    "metric = 'auc_1'\r\n",
    "checkpoint_filepath = 'MI_subtypes'\r\n",
    "\r\n",
    "checkpoint = model_checkpoint(checkpoint_filepath, monitor = metric, gen = test_gen )\r\n",
    "\r\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\r\n",
    "        factor=0.1,\r\n",
    "        patience=10,\r\n",
    "        min_lr=0.001 * 0.001)\r\n",
    "\r\n",
    "callbacks = [checkpoint, reduce_lr]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "86/86 [==============================] - 23s 266ms/step - loss: 0.6755 - accuracy: 0.7164 - auc_1: 0.8839 - val_loss: 1.7411 - val_accuracy: 0.2616 - val_auc_1: 0.4793 - val_roc_auc: 0.5341 - val_accuracy_score: 0.5077 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "86/86 [==============================] - 19s 224ms/step - loss: 0.4946 - accuracy: 0.8002 - auc_1: 0.9345 - val_loss: 0.9482 - val_accuracy: 0.6061 - val_auc_1: 0.7606 - val_roc_auc: 0.7567 - val_accuracy_score: 0.7661 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "86/86 [==============================] - 19s 226ms/step - loss: 0.4036 - accuracy: 0.8460 - auc_1: 0.9559 - val_loss: 1.2280 - val_accuracy: 0.6045 - val_auc_1: 0.7837 - val_roc_auc: 0.8271 - val_accuracy_score: 0.7443 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "86/86 [==============================] - 19s 223ms/step - loss: 0.3664 - accuracy: 0.8617 - auc_1: 0.9629 - val_loss: 0.5764 - val_accuracy: 0.7719 - val_auc_1: 0.9137 - val_roc_auc: 0.9061 - val_accuracy_score: 0.8458 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "86/86 [==============================] - 19s 226ms/step - loss: 0.3316 - accuracy: 0.8782 - auc_1: 0.9693 - val_loss: 0.6428 - val_accuracy: 0.7608 - val_auc_1: 0.9134 - val_roc_auc: 0.9181 - val_accuracy_score: 0.8442 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "86/86 [==============================] - 19s 225ms/step - loss: 0.3019 - accuracy: 0.8884 - auc_1: 0.9747 - val_loss: 0.4289 - val_accuracy: 0.8405 - val_auc_1: 0.9500 - val_roc_auc: 0.9431 - val_accuracy_score: 0.8921 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "86/86 [==============================] - 20s 227ms/step - loss: 0.2912 - accuracy: 0.8917 - auc_1: 0.9758 - val_loss: 0.5059 - val_accuracy: 0.8054 - val_auc_1: 0.9360 - val_roc_auc: 0.9402 - val_accuracy_score: 0.8724 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "86/86 [==============================] - 19s 227ms/step - loss: 0.2626 - accuracy: 0.9001 - auc_1: 0.9800 - val_loss: 0.5237 - val_accuracy: 0.7895 - val_auc_1: 0.9297 - val_roc_auc: 0.9476 - val_accuracy_score: 0.8607 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "86/86 [==============================] - 20s 228ms/step - loss: 0.2160 - accuracy: 0.9228 - auc_1: 0.9867 - val_loss: 0.3697 - val_accuracy: 0.8581 - val_auc_1: 0.9629 - val_roc_auc: 0.9581 - val_accuracy_score: 0.9075 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "86/86 [==============================] - 20s 227ms/step - loss: 0.1846 - accuracy: 0.9378 - auc_1: 0.9904 - val_loss: 0.3750 - val_accuracy: 0.8517 - val_auc_1: 0.9625 - val_roc_auc: 0.9575 - val_accuracy_score: 0.9016 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "86/86 [==============================] - 20s 228ms/step - loss: 0.1691 - accuracy: 0.9466 - auc_1: 0.9921 - val_loss: 0.3842 - val_accuracy: 0.8533 - val_auc_1: 0.9623 - val_roc_auc: 0.9579 - val_accuracy_score: 0.9032 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "86/86 [==============================] - 20s 230ms/step - loss: 0.1563 - accuracy: 0.9466 - auc_1: 0.9934 - val_loss: 0.3758 - val_accuracy: 0.8549 - val_auc_1: 0.9632 - val_roc_auc: 0.9588 - val_accuracy_score: 0.9064 - lr: 1.0000e-05\n",
      "Epoch 13/60\n",
      "86/86 [==============================] - 20s 227ms/step - loss: 0.1547 - accuracy: 0.9488 - auc_1: 0.9935 - val_loss: 0.3741 - val_accuracy: 0.8565 - val_auc_1: 0.9635 - val_roc_auc: 0.9590 - val_accuracy_score: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 14/60\n",
      "86/86 [==============================] - 20s 228ms/step - loss: 0.1530 - accuracy: 0.9491 - auc_1: 0.9937 - val_loss: 0.3733 - val_accuracy: 0.8565 - val_auc_1: 0.9637 - val_roc_auc: 0.9592 - val_accuracy_score: 0.9059 - lr: 1.0000e-06  - ETA: 0s - loss: 0.1534 - accuracy: 0.9493 - auc_1: 0.\n",
      "Epoch 15/60\n",
      "86/86 [==============================] - 20s 229ms/step - loss: 0.1529 - accuracy: 0.9491 - auc_1: 0.9937 - val_loss: 0.3735 - val_accuracy: 0.8565 - val_auc_1: 0.9637 - val_roc_auc: 0.9591 - val_accuracy_score: 0.9064 - lr: 1.0000e-06\n",
      "Epoch 16/60\n",
      "86/86 [==============================] - 20s 229ms/step - loss: 0.1528 - accuracy: 0.9491 - auc_1: 0.9937 - val_loss: 0.3746 - val_accuracy: 0.8581 - val_auc_1: 0.9634 - val_roc_auc: 0.9589 - val_accuracy_score: 0.9059 - lr: 1.0000e-06\n",
      "Epoch 17/60\n",
      "86/86 [==============================] - 20s 230ms/step - loss: 0.1526 - accuracy: 0.9491 - auc_1: 0.9937 - val_loss: 0.3735 - val_accuracy: 0.8565 - val_auc_1: 0.9637 - val_roc_auc: 0.9591 - val_accuracy_score: 0.9059 - lr: 1.0000e-06\n",
      "Epoch 18/60\n",
      "86/86 [==============================] - 20s 229ms/step - loss: 0.1525 - accuracy: 0.9488 - auc_1: 0.9937 - val_loss: 0.3741 - val_accuracy: 0.8565 - val_auc_1: 0.9635 - val_roc_auc: 0.9590 - val_accuracy_score: 0.9059 - lr: 1.0000e-06\n",
      "Epoch 19/60\n",
      "86/86 [==============================] - 19s 226ms/step - loss: 0.1524 - accuracy: 0.9488 - auc_1: 0.9937 - val_loss: 0.3744 - val_accuracy: 0.8581 - val_auc_1: 0.9635 - val_roc_auc: 0.9590 - val_accuracy_score: 0.9059 - lr: 1.0000e-06\n",
      "Epoch 20/60\n",
      "86/86 [==============================] - 20s 229ms/step - loss: 0.1523 - accuracy: 0.9499 - auc_1: 0.9937 - val_loss: 0.3743 - val_accuracy: 0.8549 - val_auc_1: 0.9635 - val_roc_auc: 0.9590 - val_accuracy_score: 0.9048 - lr: 1.0000e-06\n",
      "Epoch 21/60\n",
      "86/86 [==============================] - 20s 229ms/step - loss: 0.1521 - accuracy: 0.9499 - auc_1: 0.9937 - val_loss: 0.3746 - val_accuracy: 0.8565 - val_auc_1: 0.9634 - val_roc_auc: 0.9590 - val_accuracy_score: 0.9054 - lr: 1.0000e-06\n",
      "Epoch 22/60\n",
      "59/86 [===================>..........] - ETA: 5s - loss: 0.1479 - accuracy: 0.9535 - auc_1: 0.9940 - ETA:"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs = 60, callbacks = callbacks, validation_data = test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weights = r'C:\\Users\\likit\\OneDrive\\Desktop\\Cardio-Viz\\Code\\main\\multi_level_3_level\\AMI, IMI and NORM -- new\\original\\59_roc_0.9586.h5'\n",
    "\n",
    "model.load_weights(path_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585699858262955"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test_label\n",
    "test_gen = DataGen(X_test_scale, y_test, batch_size = len(y_test))\n",
    "\n",
    "pred = model.predict(test_gen[0][0])\n",
    "\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[236,  18,   9],\n",
       "        [ 30, 115,  19],\n",
       "        [  5,   8, 187]], dtype=int64),\n",
       " array([263, 164, 200], dtype=int64),\n",
       " array(['ASMI', 'IMI', 'NORM'], dtype=object))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(pred, axis = 1)\n",
    "\n",
    "confusion = confusion_matrix(np.argmax(y_test, axis = 1), y_pred)\n",
    "\n",
    "# np.argmax(y_test, axis = 1), y_pred\n",
    "\n",
    "confusion, np.bincount(np.argmax(y_test, axis = 1)), le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class wise accuracy: [0.90590112 0.87878788 0.93460925]\n",
      "accuracy: 0.9064327485380117\n"
     ]
    }
   ],
   "source": [
    "### Accuracy metric\n",
    "\n",
    "def metrics(y_true, y_scores):\n",
    "    y_pred = y_scores >= 0.5\n",
    "    acc = np.zeros(y_pred.shape[-1])\n",
    "    \n",
    "    for i in range(y_pred.shape[-1]):\n",
    "        acc[i] = accuracy_score(y_true[:,i], y_pred[:,i])\n",
    "    return acc, np.mean(acc)\n",
    "\n",
    "acc, mean_acc = metrics(y_test, pred)\n",
    "print(f'class wise accuracy: {acc}')\n",
    "print(f'accuracy: {mean_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_score : 0.9585699858262955\n",
      "class wise AUC : [0.96021184 0.92918664 0.98631148]\n"
     ]
    }
   ],
   "source": [
    "### Class wise AUC\n",
    "\n",
    "roc_score = roc_auc_score(y_test, pred, average='macro')\n",
    "print(f'roc_score : {roc_score}')\n",
    "\n",
    "def AUC(y_true: np.ndarray, y_pred: np.ndarray, verbose=False) -> float:\n",
    "    \"\"\"Computes the macro-average AUC score.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): list of labels\n",
    "        y_pred (np.ndarray): list of predicted probabilities\n",
    "\n",
    "    Returns:\n",
    "        float: macro-average AUC score.\n",
    "    \"\"\"\n",
    "    aucs = []\n",
    "    assert len(y_true.shape) == 2 and len(y_pred.shape) == 2, 'Predictions and labels must be 2D.'\n",
    "    for col in range(y_true.shape[1]):\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[:, col], y_pred[:, col]))\n",
    "        except ValueError as e:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f'Value error encountered for label {col}, likely due to using mixup or '\n",
    "                    f'lack of full label presence. Setting AUC to accuracy. '\n",
    "                    f'Original error was: {str(e)}.'\n",
    "                )\n",
    "            aucs.append((y_pred == y_true).sum() / len(y_pred))\n",
    "    return np.array(aucs)\n",
    "\n",
    "class_auc = AUC(y_test, pred)\n",
    "print(f'class wise AUC : {class_auc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8758032167085021,\n",
       " 0.9585699858262955,\n",
       " array([0.5       , 0.87537245, 0.87580322, 0.87309328, 0.8611916 ,\n",
       "        0.85737439, 0.84317032, 0.82782609, 0.78438662,        nan]),\n",
       " array([0.33333333, 0.81472621, 0.84077618, 0.85247209, 0.85955056,\n",
       "        0.87149918, 0.89445438, 0.91013384, 0.93986637,        nan]),\n",
       " array([1.        , 0.94577352, 0.9138756 , 0.89473684, 0.86283892,\n",
       "        0.84370016, 0.79744817, 0.75917065, 0.67304625, 0.        ]),\n",
       " array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "        0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multi_threshold_precision_recall(y_true: np.ndarray, y_pred: np.ndarray, thresholds: np.ndarray) :\n",
    "    \n",
    "    # Expand analysis to number of thresholds\n",
    "    y_pred_bin = np.repeat(y_pred[None, :, :], len(thresholds), axis=0) >= thresholds[:, None, None]\n",
    "    y_true_bin = np.repeat(y_true[None, :, :], len(thresholds), axis=0)\n",
    "\n",
    "    # Compute true positives\n",
    "    TP = np.sum(np.logical_and(y_true, y_pred_bin), axis=2)\n",
    "\n",
    "    # Compute macro-average precision handling all warnings\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        den = np.sum(y_pred_bin, axis=2)\n",
    "        precision = TP / den\n",
    "        precision[den == 0] = np.nan\n",
    "        with warnings.catch_warnings():  # for nan slices\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            av_precision = np.nanmean(precision, axis=1)\n",
    "\n",
    "    # Compute macro-average recall\n",
    "    recall = TP / np.sum(y_true_bin, axis=2)\n",
    "    av_recall = np.mean(recall, axis=1)\n",
    "\n",
    "    return av_precision, av_recall\n",
    "\n",
    "\n",
    "def metric_summary(y_true: np.ndarray, y_pred: np.ndarray, num_thresholds: int = 10) :\n",
    "    \n",
    "    thresholds = np.arange(0.00, 1.01, 1. / (num_thresholds - 1), float)\n",
    "    average_precisions, average_recalls = multi_threshold_precision_recall(\n",
    "        y_true, y_pred, thresholds\n",
    "    )\n",
    "    f_scores = 2 * (average_precisions * average_recalls) / (average_precisions + average_recalls)\n",
    "    auc = np.array(AUC(y_true, y_pred, verbose=True)).mean()\n",
    "    return (\n",
    "        f_scores[np.nanargmax(f_scores)],\n",
    "        auc,\n",
    "        f_scores,\n",
    "        average_precisions,\n",
    "        average_recalls,\n",
    "        thresholds\n",
    "    )\n",
    "\n",
    "metric_summary(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ASMI       0.88      0.90      0.89       263\n",
      "         IMI       0.81      0.70      0.75       164\n",
      "        NORM       0.87      0.93      0.90       200\n",
      "\n",
      "   micro avg       0.86      0.85      0.86       627\n",
      "   macro avg       0.86      0.84      0.85       627\n",
      "weighted avg       0.86      0.85      0.86       627\n",
      " samples avg       0.85      0.85      0.85       627\n",
      "\n",
      "C:\\Users\\likit\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_values = pred >= 0.5\n",
    "\n",
    "report = classification_report(y_test, pred_values, target_names = le.classes_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\r\n",
    "\r\n",
    "# Plotting\r\n",
    "path = 'ptb/'\r\n",
    "sample = 'record_sample'\r\n",
    "\r\n",
    "test_data = np.array([wfdb.rdsamp(path+sample)[0] ])\r\n",
    "test_data_scale = apply_scaler(test_data, scaler)\r\n",
    "\r\n",
    "test_data_scale = np.transpose(test_data_scale[..., np.newaxis], (0,2,1,3))\r\n",
    "    \r\n",
    "\r\n",
    "### To get layer names\r\n",
    "# for layer in model.layers:\r\n",
    "#     print(layer.name)\r\n",
    "\r\n",
    "attention_layer = tf.keras.models.Model(inputs = model.input, outputs = [model.get_layer(\"beat_att\").output, \r\n",
    "                                                                                        model.get_layer(\"rhythm_att\").output,\r\n",
    "                                                                                        model.get_layer(\"channel_att\").output])\r\n",
    "beat, rhythm, channel = attention_layer(test_data_scale)\r\n",
    "\r\n",
    "beat_att = np.asarray(beat[1]); rhythm_att = np.asarray(rhythm[1]); channel_att = np.asarray(channel[1])\r\n",
    "\r\n",
    "beat_att = beat_att.reshape(240, 13)\r\n",
    "beat_only_att = np.empty((240,beat_size))\r\n",
    "for i in range(beat_att.shape[0]):\r\n",
    "    beat_only_att[i] = resample(beat_att[i], beat_size)\r\n",
    "\r\n",
    "beat_att = np.copy(beat_only_att)\r\n",
    "\r\n",
    "## Rhytm\r\n",
    "rhythm_att = rhythm_att.reshape(12*20)\r\n",
    "for i in range(12*20):\r\n",
    "    beat_att[i] = beat_att[i] * rhythm_att[i]\r\n",
    "\r\n",
    "\r\n",
    "# Channel\r\n",
    "beat_att = beat_att.reshape(12, 20*50)\r\n",
    "channel_att = channel_att.flatten()\r\n",
    "for i in range(12):\r\n",
    "    beat_att[i] = beat_att[i] * channel_att[i]\r\n",
    "    \r\n",
    "scores = np.copy(beat_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(test_data_scale), le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate Beat level using channel level\n",
    "\n",
    "beat_channel = np.copy(beat_only_att.reshape(12, 20*50))\n",
    "\n",
    "for i in range(12):\n",
    "    beat_channel[i] = beat_channel[i] * channel_att[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nor = (scores.flatten() - scores.flatten().min(keepdims=True)) / (scores.flatten().max( keepdims=True) - scores.flatten().min(keepdims=True))\r\n",
    "scores_nor = scores_nor.reshape(12, 1000)\r\n",
    "\r\n",
    "\r\n",
    "beat_only_att_nor = (beat_only_att.flatten() - beat_only_att.flatten().min(keepdims=True)) / (beat_only_att.flatten().max( keepdims=True) - beat_only_att.flatten().min(keepdims=True))\r\n",
    "beat_only_att_nor = beat_only_att_nor.reshape(12, 1000)\r\n",
    "beat_only_att = beat_only_att.reshape(12, 1000)\r\n",
    "\r\n",
    "ch_info = ['I',\r\n",
    "           'II',\r\n",
    "           'III',\r\n",
    "           'AVR',\r\n",
    "           'AVL',\r\n",
    "           'AVF',\r\n",
    "           'V1',\r\n",
    "           'V2',\r\n",
    "           'V3',\r\n",
    "           'V4',\r\n",
    "           'V5',\r\n",
    "           'V6']\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "fig, axs = plt.subplots(12, figsize = (45, 30))\r\n",
    "x = np.arange(1000)\r\n",
    "\r\n",
    "\r\n",
    "fig, axs = plt.subplots(12, figsize = (35, 25))\r\n",
    "x = np.arange(1000)\r\n",
    "\r\n",
    "for i, (ax, ch) in enumerate(zip(axs, ch_info)):\r\n",
    "    im = ax.scatter(np.arange(len(test_data[:,:,i].squeeze())), test_data[:,:,i].squeeze(), cmap = 'hot_r', c= beat_channel[i])\r\n",
    "    plt.colorbar(im, ax = ax)\r\n",
    "    ax.plot(test_data[:,:,i].squeeze())\r\n",
    "    ax.set_title(ch, fontsize = 30)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\r\n",
    "import plotly.offline as pyo\r\n",
    "\r\n",
    "pyo.init_notebook_mode()\r\n",
    "\r\n",
    "fig = px.bar(channel_att)\r\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf': conda)",
   "name": "python37764bittfgpucondad1048e2c1cb249e3861f34c4a36205b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "8ec611c835db78d84b6792c6109a40fde2d82a4b51b510d36b5492580aff59ca"
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": "50",
    "lenVar": "100"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}